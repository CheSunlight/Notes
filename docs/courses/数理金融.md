# 数理金融
2022春季 杨招军

<!-- pagebreak -->

## Discrete-Time Dynamic Programming

### Basic Structure
- State Transfer System
  $$
  x_{k+1} = f_k(x_k,\ u_k),\ k=0,\ 1,\ \cdots,\ N-1
  $$
  - $k$: discrete-time
  - $x_k$: state
  - $u_k$: control (dicision to be selected), $u_k \in U$ with a control set $U$
  - $f_k$: rule (a.k.a. state transfer function)
  - $N$: horizon
- Policy and Value Functional
    - Policy $\pi=(\mu_0,\ \mu_1,\ \cdots,\ \mu_{N-1})$ maps states into controls, i.e., $u_k=\mu_k(x_k)$ (can be understood as strategy).
    - <mark>Value functional</mark> of $\pi$ starting at $x_0$ is 
      $$
      J_{\pi}(x_0) = g_{N}(x_{N}) + \sum\limits_{k=0}^{N-1} g_k(x_k,\ u_k)
      $$where $g(\cdot)$ is the payoff of control under specific discete-time and state.
    - <mark>Value function</mark> $V_0(x_0)=\max_{\pi}\ J_{\pi}(x_0)$ and the corresponding policy is the optimal policy $\pi^{*}$
      > [!NOTE]
      > Difference between functional and function: the independent variable of a functional is function.
      The independent variable of $J_{\pi}(x_0)$ is $\pi$, whose components are functions.
- Example
  - The Shortest Path Problem
    ![](image/2022-02-16-12-12-32.png)
  - $x_0=A,\ x_1 \in \{B_1,\ B_2\},\ \cdots,\ x_6=G$
  - $g_5(F_1,\ G)=-4,\ g_4(E_1,\ F_1)=-3,\ \cdots$

### Principle of Optimality
- <mark>Definition</mark>

  From any point on an optimal trajectory, the remaining trajectory is optimal for the corresponding problem initiated at that point.
  $$
  V_k(x_k) = \underset{u_k \in U}{\max}\ \left[ g_k(x_k,\ u_k) + V_{k+1}(f_k(x_k,\ u_k)) \right] 
  $$
- Developed by Richard Bellman (1953).
- To solve the optimality is to solve all the tail subproblem. For example, consider the shortest path problem above, we start at $G$ and then go backwards to get optimal policies at each state.
  $$
  V_6(G) = 0,\ V_5(F_1) = -4,\ V_5(F_2) = -3 \\
  \ \\
  \begin{aligned}
   g_4(E_1,\ F_1) + V_5(F_1) &= -7,\ & g_4(E_1,\ F_2) + V_5(F_2) &= -8 \implies & V_4(E_1) &= -7 \\
   g_4(E_2,\ F_1) + V_5(F_1) &= -9,\ & g_4(E_2,\ F_2) + V_5(F_2) &= -5 \implies & V_4(E_2) &= -5 \\
   g_4(E_3,\ F_1) + V_5(F_1) &= -10,\ & g_4(E_3,\ F_2) + V_5(F_2) &= -9 \implies & V_4(E_3) &= -9 \\
   \ \\
   g_3(D_1,\ E_1) + V_4(E_1) &= -9,\ & g_3(D_1,\ E_2) + V_4(E_2) &= -7 \implies & V_3(D_1) &= -7 \\
   g_3(D_2,\ E_2) + V_4(E_2) &= -6,\ & g_3(D_2,\ E_3) + V_4(E_3) &= -11 \implies & V_3(D_2) &= -6 \\
   g_3(D_3,\ E_2) + V_4(E_2) &= -8,\ & g_3(D_3,\ E_3) + V_4(E_3) &= -12 \implies & V_3(D_3) &= -8 \\
   \ \\
   g_2(C_1,\ D_1) + V_3(D_1) &= -13,\ & g_2(C_1,\ D_2) + V_3(D_2) &= -14 \implies & V_2(C_1) &= -13 \\
   g_2(C_2,\ D_1) + V_3(D_1) &= -10,\ & g_2(C_2,\ D_2) + V_3(D_2) &= -11 \implies & V_2(C_2) &= -10 \\
   g_2(C_3,\ D_2) + V_3(D_2) &= -9,\ & g_2(C_3,\ D_3) + V_3(D_3) &= -11 \implies & V_2(C_3) &= -9 \\
   g_2(C_4,\ D_2) + V_3(D_2) &= -14,\ & g_2(C_4,\ D_3) + V_3(D_3) &= -12 \implies & V_2(C_4) &= -12 \\
  \end{aligned}\\
   \ \\
  \begin{aligned}
   g_1(B_1,\ C_1) + V_2(C_1) &= -14,\ & g_1(B_1,\ C_2) + V_2(C_2) &= -13,\ & g_1(B_1,\ C_3) + V_2(C_3) &= -15 \implies & V_2(B_1) &= -13 \\
   g_1(B_2,\ C_2) + V_2(C_2) &= -18,\ & g_1(B_2,\ C_3) + V_2(C_3) &= -16,\ & g_1(B_2,\ C_4) + V_2(C_4) &= -18 \implies & V_2(B_2) &= -16 \\
  \end{aligned}\\
   \ \\
   g_0(A,\ B_1) + V_1(B_1) = -18,\ g_0(A,\ B_2) + V_1(B_2) = -19 \implies V_0(A) = -18
  $$which means the optimal path is $A\to B_1\to C_2\to D_1\to E_2\to F_2\to G$.

### Stochastic Dynamic Programming
- State $x_{k+1}=f_k(x_k,\ u_k,\ z_k)$ where $z_k$ is a random variable with probability distribution $\mathrm{P}_k(\cdot|x_k,\ u_k)$
- Value functional becomes 
  $$
  \mathrm{E}\left( g_N(x_N)+\sum\limits_{k=0}^{N-1} g_k(x_k,\ u_k,\ z_k) \right) 
  $$
- Formula of Principle of Optimality becomes 
  $$
  V_k(x_k) = \underset{u_k \in U}{\max}\ \mathrm{E}\left[ g_k(x_k,\ u_k,\ z_k) + V_{k+1}(f_k(x_k,\ u_k,\ z_k)) \right] 
  $$

<!-- pagebreak -->

## Continuous-Time Deterministic Dynamic Programming
### Basic Structure
- Control System
  $$
  \begin{cases}
   \frac{\mathrm{d}x}{\mathrm{d}t} = b(t,\ x(t),\ u(t)),& t \in [0,\ T] \\
   x(0) = x_0
  \end{cases}
  $$where the initial value $x_0 \in \mathbb{R}$, the control $u: [0,\ T] \to U$ with a metric space $U$ and the map $b: [0,\ T]\times \mathbb{R}\times U \to \mathbb{R}$.
  Consider $s \in [0,\ T)$ and $y \in \mathbb{R}$, the control system becomes
  $$
  \begin{cases}
    \frac{\mathrm{d}x}{\mathrm{d}t} = b(t,\ x(t),\ u(t)),& t \in [s,\ T] \\
    x(s) = y
  \end{cases}
  $$
- Value Functional
  $$
  J(s,\ y;\ u(\cdot)) = h(x(T)) + \int_s^{T} f(t,\ x(t),\ u(t))~\mathrm{d}t
  $$for some given payoff maps $f$ and $h$.
- Value Function
  $$
  V(s,\ y) =
  \begin{cases}
     \underset{u \in U}{\mathrm{sup}}\ J(s,\ y;\ u(\cdot)),& s \in [0,\ T) \\
     h(y),& s=T
  \end{cases}
  $$

### Principle of Optimality
![](image/2022-02-23-23-28-56.png)
The equation above is called the <mark>dynamic programming equation</mark>.
- If the value function $V \in \mathbb{C}^{1}([0,\ T]\times \mathbb{R})$ (the first order derivatives are continuous), then $V$ satisfies the <mark>HJB (Hamilton-Jacobi-Bellman) equation</mark>: 
  $$
  \begin{cases}
    V_t + \underset{u \in U}{\mathrm{sup}}\ [b(t,\ x,\ u)V_x + f(t,\ x,\ u)] = 0 \\
    V(t=T,\ x) = h(x)
  \end{cases}
  $$where $x(t)$ and $u(t)$ are simply written as $x$ and $u$.
  <details>
  <summary>Proof</summary>

    Fix a $u \in U$. By the principle of optimality, we have
    $$
     \int_{s}^{\hat{s}} f(t,\ x,\ u)  ~\mathrm{d}t + V(\hat{s},\ x(\hat{s})) \leqslant V(s,\ y)
    $$Let $\hat{s} \to s$, then we can write 
    $$
     \int_{s}^{\hat{s}} f(t,\ x,\ u)  ~\mathrm{d}t = (\hat{s}-s)f(s,\ x(s),\ u(s)) + \omicron(\hat{s}-s) \implies \frac{\int_{s}^{\hat{s}} f(t,\ x,\ u)  ~\mathrm{d}t}{\hat{s}-s} = f(s,\ x(s),\ u(s))
    $$and 
    $$
     V(\hat{s},\ x(\hat{s})) = V(s,\ x(s)) +V_t|_{t=s}(\hat{s}-s)+\omicron(\hat{s}-s)+V_x|_{x=x(s)}(x(\hat{s})-x(s))+\omicron(x(\hat{s})-x(s)) \\
     \implies \frac{V(\hat{s},\ x(\hat{s}))-V(s,\ x(s))}{\hat{s}-s} = V_t|_{t=s} + V_x|_{x=x(s)}b(s,\ x(s),\ u(s))
    $$by Taylor expansion.
    > [!TIP]
    > When $\hat{s} \to s$, $\frac{\omicron(x(\hat{s})-x(s))}{\hat{s}-s}=\frac{\omicron(x(\hat{s})-x(s))}{x(\hat{s})-x(s)}\frac{x(\hat{s})-x(s)}{\hat{s}-s}=\frac{\omicron(x(\hat{s})-x(s))}{x(\hat{s})-x(s)}b(s,\ x(s),\ u(s))=0$. 

    Thus, we have 
    $$
    f(s,\ x(s),\ u(s)) + V_t|_{t=s} + V_x|_{x=x(s)}b(s,\ x(s),\ u(s)) \leqslant 0
    $$Then for any $u \in U$, we obtain 
    $$
    V_t|_{t=s} + \underset{u \in U}{\mathrm{sup}}[ f(s,\ x(s),\ u(s)) + V_x|_{x=x(s)}b(s,\ x(s),\ u(s)) ] \leqslant 0
    $$On the other hand, by the definition of supremum, $\forall \varepsilon>0$ with $\hat{s}-s>0$ small enough, $\exists u \in U$ s.t. 
    $$
    V(s,\ y) - \varepsilon(\hat{s}-s) \leqslant \int_{s}^{\hat{s}} f(t,\ x,\ u)  ~\mathrm{d}t + V(\hat{s},\ x(\hat{s}))
    $$Using the same method above, this yeilds
    $$
    f(s,\ x(s),\ u(s)) + V_t|_{t=s} + V_x|_{x=x(s)}b(s,\ x(s),\ u(s)) \geqslant -\varepsilon
    $$which means 
    $$
    V_t|_{t=s} + \underset{u \in U}{\mathrm{sup}}[ f(s,\ x(s),\ u(s)) + V_x|_{x=x(s)}b(s,\ x(s),\ u(s)) ] \geqslant 0
    $$Hence, we finish the proof.
  </details>
- Example
  - The neoclassical production function is 
    $$
    Y = F(K,\ L) 
    $$where $Y$ is output, $K$ and $L$ are time-varying capital input and constant labor input, respectively, and $F(\cdot,\ \cdot)$ is homogeneous of degree one, i.e., $F(\alpha K,\ \alpha L)=\alpha F(K,\ L),\ \forall \alpha>0$.

    Thus, if we take labor $L$ to be fixed, per capita output can be expressed as 
    $$
    y = \frac{Y}{L} = F\left( \frac{K}{L}, 1 \right)  := f(k)
    $$where $k=\frac{K}{L}$.
  - The well-known macroeconomic identities show that 
    $$
    \begin{cases}
      I = Y - C \\
      \mathrm{d}K = I \mathrm{d}t - \delta K \mathrm{d}t
    \end{cases}
    $$where $I$ represents investment, $C$ is total consumption and $\delta$ is the rate of depreciation of capital.

    Let per capita consumption $c=\frac{C}{L}$, we obtain 
    $$
    \frac{\mathrm{d}k}{\mathrm{d}t} = \frac{1}{L}\frac{\mathrm{d}K}{\mathrm{d}t} = \frac{I-\delta K}{L} = \frac{Y}{L} - \frac{C}{L} - \delta \frac{K}{L} = f(k) - c - \delta k
    $$which means the control system can be written as 
    $$
    \begin{cases}
      \frac{\mathrm{d}k}{\mathrm{d}t} = f(k) - c - \delta k\\
      k(0) = k_0
    \end{cases}
    $$given initial per capita capital $k_0$.
  - Ramsey (1928) proposed the idea of a bliss point, an accumulation point of a sequence of consumption decisions representing the nonattainable, ideal consumption goal of the consumer. In math form, we write the bliss point 
    $$
    B=\underset{c\geqslant 0}{\mathrm{sup}}\ U(c)>0
    $$where $U(c)$ is the utility experienced as a result of per capita consumption $c$.

    Consumers want to minimize the gap between utility and the bliss point, so the value functional of the control system can be written as 
    $$
    J(0,\ k_0;\ c(\cdot)) = \int_{0}^{\infty} U(c)-B ~\mathrm{d}t 
    $$and the value function 
    $$
    V(s,\ k_0) = \underset{c}{\mathrm{sup}}\ \int_{0}^{\infty} U(c)-B ~\mathrm{d}t = V(k_0)
    $$is time-homogeneous.
  - Assume $U(c) = B - e^{-\lambda c}$ with constant $\lambda>0$. By HJB equation we know that 
    $$
    V_t + \underset{c}{\mathrm{sup}}\ \left[(f(k)-c-\delta k) V_k - e^{-\lambda c}  \right]  = 0 \\
    $$Since the value function is time-homogeneous, $V_t=0$. The first-order derivative of the function in the bracket w.r.t. $c$ is $-V_k + \lambda e^{-\lambda c}$, and the second-order derivative w.r.t. $c$ is $-\lambda^{2}e^{-\lambda c}$, which means the function reaches an unique maximum when $c$ satisfies $\lambda e^{-\lambda c} = V_k$. Thus, the equation above becomes 
    $$
    \begin{aligned}
     (f(k^{*}) - c^{*} - \delta k^{*}) \lambda e^{-\lambda c^{*}} - e^{-\lambda c^{*}} &= 0 \\
     c^{*} &= f(k^{*}) - \delta k^{*} - \frac{1}{\lambda}
    \end{aligned}
    $$and we have 
    $$
    \frac{\mathrm{d}k^{*}}{\mathrm{d}t} = f(k^{*}) - c^{*} - \delta k^{*} = \frac{1}{\lambda}
    $$which means 
    $$
    k^{*} = k_0 + \frac{t}{\lambda}
    $$
    
<!-- pagebreak -->

## Wiener Process (Brownian Motion)

### Symmetric Random Walk
- Repeatedly toss a fair coin, denote the successive outcomes of the tosses by $\omega_1,\ \omega_2,\ \cdots$.
- Let $X_j=\begin{cases}1,& \omega_j = H \\ -1,& \omega_j = T \\ \end{cases}$ for outcome "Head" or "Tail" and define 
  $$
  M_k = \sum\limits_{j=1}^{k} X_j \quad (k=1,\ 2,\ \cdots)
  $$with $M_0=0$, then the process $M$ is a symmetric random walk.
- A random walk has <mark>independent increments</mark>. Each increment $M_{k_{i+1}} - M_{k_i}$ has <mark>expected value $0$ and variance $k_{i+1}-k_i$</mark> since $M_{k_{i+1}} - M_{k_i} = X_{k_i+1} + X_{k_i+2} + \cdots + X_{k_{i+1}}$.
- The symmetric random walk is a <mark>martingale</mark> since $\mathrm{E}(M_{k_{i+1}}|\mathcal{F}_{k_i})=M_{k_i}$.
- The <mark>quadratic variation</mark> $[M,\ M]_k = \sum\limits_{j=1}^{k} (M_j-M_{j-1})^{2} = \sum\limits_{j=1}^{k} X_j^{2} = k$.

### Scaled Symmetric Random Walk
$$
W^{n}(t) = \frac{1}{\sqrt{n}}M_{nt}\quad (t\geqslant 0)
$$where $n$ is a fixed integer.
- If $nt$ is not an integer, we define $W^{n}(t)$ by linear interpolation between its values at the nearest points $s$ and $u$ to the left and right of $t$ for which $ns$ and $nu$ are integers.
- By the CLT (Central Limit Theorem), when $n\to \infty$, $M_{nt} \sim N(0,\ t)$ since $\mathrm{E}(M_{nt}) = 0$ and $\mathrm{Var}(M_{nt})=nt$. Thus, <mark>$W^{n}(t)\sim N(0,\ t)$ as $n\to \infty$</mark>.

### Arithmetic and Geometric Brownian Motion
- Arithmetic Brownian Motion
  $$
  S(t) = at + b W(t)\quad (t\geqslant 0)
  $$where $W(t)\sim N(0,\ t)$.
  - Shortcoming: Asset prices can be negative.
- <mark>Geometric Brownian Motion (GBM)</mark>
  $$
  S(t) = S(0)e^{\sigma W(t) + (\mu-\frac{1}{2}\sigma^{2})t}
  $$
- GBM is a limit of a Binomial model.
  <details>
  <summary>Proof</summary>

  Consider a binomial model with $n$ steps per unit time and expected return rate per unit time, $\mu$. The up factor $u_n=e^{\frac{\sigma}{\sqrt{n}}}$ with probablility $p_n=\frac{\left( 1+\frac{\mu}{n} \right) - d_n}{u_n-d_n}$ and the down factor $d_n=e^{-\frac{\sigma}{\sqrt{n}}}$ with probability $1-p_n=\frac{u_n-\left( 1+\frac{\mu}{n} \right) }{u_n-d_n}$.

  Let $nt$ be an integer, define 
  $$
  M_{nt} = \sum\limits_{k=1}^{nt} X_{k,\ n}
  $$where $\{X_{k,\ n} \}$ are i.i.d. random variables representing the rise or decrease of the stock price with $\mathrm{P}(X_{k,\ n}=1)=p_n$ and $\mathrm{P}(X_{k,\ n}=-1)=1-p_n$. 
    
  When $p_n=\frac{1}{2}$, $\frac{1}{\sqrt{n}}M_{nt}$ is a scaled symmetric random walk and tends to be a Wiener process $W(t)$ as $n\to \infty$. Generally, for any $p_n$, the mgf of $\frac{1}{\sqrt{n}}M_{nt}$ is 
  $$
  M_{\frac{1}{\sqrt{n}}M_{nt}}(\theta) = \mathrm{E}\left( e^{\theta \frac{1}{\sqrt{n}}M_{nt}} \right) = \mathrm{E}\left( \prod_{k=1}^{nt} e^{\theta \frac{1}{\sqrt{n}}X_{k,\ n} } \right) = \left[ e^{\frac{\theta}{\sqrt{n}}}\frac{\left( 1+\frac{\mu}{n} \right) - e^{-\frac{\sigma}{\sqrt{n}}}}{e^{\frac{\sigma}{\sqrt{n}}}-e^{-\frac{\sigma}{\sqrt{n}}}} + e^{-\frac{\theta}{\sqrt{n}}}\frac{e^{\frac{\sigma}{\sqrt{n}}}-\left( 1+\frac{\mu}{n} \right) }{e^{\frac{\sigma}{\sqrt{n}}}-e^{-\frac{\sigma}{\sqrt{n}}}} \right]^{nt}
  $$Then, let $x=\frac{1}{\sqrt{n}}$, when $n\to \infty$, we have 
  $$
  \begin{aligned}
   \lim\limits_{n \to \infty} \log M_{\frac{1}{\sqrt{n}}M_{nt}}(\theta) &= \lim\limits_{x \to 0^{+}} \frac{t}{x^{2}} \log \left[ e^{\theta x} \frac{(1+\mu x^{2})-e^{-\sigma x}}{e^{\sigma x}-e^{-\sigma x}} + e^{-\theta x} \frac{e^{\sigma x}-(1+\mu x^{2})}{e^{\sigma x}-e^{-\sigma x}} \right]\\
   &= \lim\limits_{x \to 0^{+}} \frac{t}{x^{2}} \log \left[ \frac{(1+\mu x^{2})(e^{\theta x}-e^{-\theta x})+e^{(\sigma-\theta) x}-e^{-(\sigma-\theta) x}}{e^{\sigma x}-e^{-\sigma x}} \right]\\
   &= \lim\limits_{x \to 0^{+}} \frac{t}{x^{2}} \log \left[ \frac{(1+\mu x^{2})\sinh \theta x+\sinh (\sigma-\theta)}{\sinh \sigma x} \right]\\
   &= \lim\limits_{x \to 0^{+}} \frac{t}{x^{2}} \log \left[ \frac{(1+\mu x^{2})\sinh \theta x+\sinh \sigma x \cosh \theta x - \cosh \sigma x \sinh \theta x}{\sinh \sigma x} \right]\\
   &= \lim\limits_{x \to 0^{+}} \frac{t}{x^{2}} \log \left[\cosh \theta x + \frac{(1+\mu x^{2} - \cosh \sigma x)\sinh \theta x}{\sinh \sigma x} \right]\\
   &= \lim\limits_{x \to 0^{+}} \frac{t}{x^{2}} \log \left[1+\frac{1}{2}\theta^{2}x^{2} + \omicron(x^{4}) + \frac{\left[1+\mu x^{2} - \left( 1+\frac{1}{2}\sigma^{2}x^{2}+\omicron(x^{4}) \right) \right](\theta x + \omicron(x^{3}))}{\sigma x + \omicron(x^{3})} \right]\\
   &= \lim\limits_{x \to 0^{+}} \frac{t}{x^{2}} \log \left[1+\frac{1}{2}\theta^{2}x^{2} + \omicron(x^{4}) + \frac{\left( \mu - \frac{1}{2}\sigma^{2} \right)\theta x^{3} + \omicron(x^{5})}{\sigma x + \omicron(x^{3})} \right]\\
   &= \lim\limits_{x \to 0^{+}} \frac{t}{x^{2}} \log \left[1+\frac{1}{2}\theta^{2}x^{2} + \omicron(x^{4}) + \frac{\left( \mu - \frac{1}{2}\sigma^{2} \right)\theta x^{3}(1 + \omicron(x^{2}))}{\sigma x(1 + \omicron(x^{2}))} \right]\\
   &= \lim\limits_{x \to 0^{+}} \frac{t}{x^{2}} \log \left[1+\frac{1}{2}\theta^{2}x^{2}  + \frac{\left( \mu - \frac{1}{2}\sigma^{2} \right)\theta x^{2}}{\sigma}+ \omicron(x^{4}) \right]\\
   &= \lim\limits_{x \to 0^{+}} \frac{t}{x^{2}} \left[\frac{1}{2}\theta^{2}x^{2}  + \frac{\left( \mu - \frac{1}{2}\sigma^{2} \right)\theta x^{2}}{\sigma}+ \omicron(x^{4}) \right]\\
   &= \left[\frac{1}{2}\theta^{2}  + \frac{\left( \mu - \frac{1}{2}\sigma^{2} \right)\theta }{\sigma} \right]t\\
   &= \frac{\left( \mu - \frac{1}{2}\sigma^{2} \right)t }{\sigma}\theta + \frac{1}{2}t \theta^{2}\\
  \end{aligned}
  $$

  > [!TIP]
  > $\sinh x = \frac{e^{x} - e^{-x}}{2}$, $\cosh x = \frac{e^{x} + e^{-x}}{2}$ and $\sinh (x-y) = \sinh x \cosh y - \cosh x \sinh y$.<br>
  When $x\to 0$, we have $\sinh x = x + \omicron(x^{3})$, $\cosh x = 1+\frac{1}{2}x^{2}+\omicron(x^{4})$ and $\log (1+x) = x + \omicron(x^{2})$.

  Thus, $\lim\limits_{n \to \infty} M_{\frac{1}{\sqrt{n}}M_{nt}}(\theta) = e^{\frac{\left( \mu - \frac{1}{2}\sigma^{2} \right)t }{\sigma}\theta + \frac{1}{2}t \theta^{2}}$ is the mgf of $N\left( \frac{\left( \mu - \frac{1}{2}\sigma^{2} \right)t }{\sigma},\ t \right)$, which means $\frac{1}{\sqrt{n}}M_{nt} \sim N\left( \frac{\left( \mu - \frac{1}{2}\sigma^{2} \right)t }{\sigma},\ t \right)$ as $n\to \infty$.

  Assume the stock price rises $x$ times, then it decreases $nt-x$ times. Note that $x-(nt-x)=M_{nt}$, which means $x=\frac{1}{2}(nt-M_{nt})$ and $nt-x=\frac{1}{2}(nt-M_{nt})$. Thus, the stock price at time $t$ satisfies  
  $$
  \begin{aligned}
   S_n(t) &= S(0) u_n^{\frac{1}{2}(nt+M_{nt})}d_n^{\frac{1}{2}(nt-M_{nt})}\\
   &= S(0) e^{\frac{1}{2\sqrt{n}}\sigma(nt+M_{nt})}e^{-\frac{1}{2\sqrt{n}}\sigma(nt-M_{nt})}\\
   &= S(0) e^{\sigma\frac{1}{\sqrt{n}} M_{nt}}\\
   &= S(0) e^{\left( \mu - \frac{1}{2}\sigma^{2} \right)t + \sigma W(t)}\quad (n\to \infty)
  \end{aligned}
  $$
- In a <mark>risk-neutral</mark> world, the $\mu$ is just the risk-free rate per unit time, $r$.

### Properties of Wiener Process
- $W(t)$ with $W(0)=0$ is a Wiener process if all the increments $\{W(t_i) - W(t_{i-1})\}_{i=1}^{n}$ are independent and each is normally distributed with expeceted value $0$ and variance $t_i - t_{i-1}$.
- $\mathrm{Cov}(W(t_1),\ W(t_2)) = \mathrm{Cov}(W(t_1),\ W(t_1) + (W(t_2)-W(t_1))) = t_1$
- Wiener process is a martingale since $\mathrm{E}(W(t_2)|\mathcal{F}_1) = W(t_1) + \mathrm{E}(W(t_2)-W(t_1)|\mathcal{F}_1) = W(t_1)$.
- The quadratic variation $[W,\ W]_T = T$ and thus $(\mathrm{d}W(t))^{2}=\mathrm{d}t$
- $\mathrm{d}W(t)\mathrm{d}t=0$, $(\mathrm{d}t)^{2}=0$ and $\mathrm{d}W(t)=\phi \sqrt{\mathrm{d}t}$ where $\phi \sim N(0,\ 1)$.

### It$\mathrm{\hat{o}}$'s Formula
$$
\mathrm{d}f(t,\ W(t)) = f_t(t,\ W(t))\mathrm{d}t + f_x(t,\ W(t))\mathrm{d}W(t) + \frac{1}{2}f_{xx}(t,\ W(t))\mathrm{d}t
$$

<!-- pagebreak -->

## Probability Theory

### Probability Space
- $\sigma$-algebra

  If $\Omega$ a given set, then a $\sigma$-algebra $\mathcal{F}$ on $\Omega$ is a family of subsets of $\Omega$ with the following properties: 
  - $\emptyset \in \mathcal{F}$;
  - If a set $F \in \mathcal{F}$, then $F^{c}=\Omega \setminus F \in \mathcal{F}$;
  - If sets $A_1,\ A_2,\ \cdots \in \mathcal{F}$, then set $A = \cup_{i=1}^{\infty} A_i \in \mathcal{F}$.
  The pair $(\Omega,\ \mathcal{F})$ is called a <mark>measurable space</mark>.

  > [!NOTE]
  > A $\sigma$-algebra is a field (since a field is a special ring, it is also a ring), so we also called it a $\sigma$-field. Borel field $\mathcal{B}$ is a common $\sigma$-field.

- Probability measure

  A probability measure $\mathrm{P}$ on a measurable space $(\Omega,\ \mathcal{F})$ is a function $\mathrm{P}:\ \mathcal{F} \to [0,\ 1]$ s.t. 
  - $\mathrm{P}(\emptyset)=0$ and $\mathrm{P}(\Omega)=1$;
  - If $A_1,\ A_2,\ \cdots \in \mathcal{F}$ and $A_i \cap A_j = \emptyset \ (i\neq j)$, then $\mathrm{P}\left( \cup_{i=1}^{\infty} A_i \right) = \sum\limits_{i=1}^{\infty} \mathrm{P}(A_i) $.

  The triple $(\Omega,\ \mathcal{F},\ \mathrm{P})$ is called a <mark>probability space</mark>.

- $\mathcal{F}$-measurable
  Given a probability space $(\Omega,\ \mathcal{F},\ \mathrm{P})$, a function $f:\ \Omega \to \mathbb{R}^{n}$ is $\mathcal{F}$-measurable if $\forall $ open sets $U \in \mathbb{R}^{n}$, $f ^{-1} (U) := \{\omega \in \Omega; f(\omega)\in U\} \in \mathcal{F}$. A <mark>random variable</mark> $X$ is an $\mathcal{F}$-measurable function $X:\ \Omega \to \mathbb{R}^{n}$.

- Distribution

  A random variable $X$ induces a probability measure $\mu_{X}$ on $\mathbb{R}^{n}$, defined by $\mu_{X}(U) = \mathrm{P}(X ^{-1}(U))$. $\mu_{X}$ is called the distribution of $X$.

### Expectation

- Definition

  Let $X$ be a random variable on a probability space $(\Omega,\ \mathcal{F},\ \mathrm{P})$. The expectation of $X$ is 
  $$
  \mathrm{E}(X) = \int_\Omega X(\omega) \mathrm{d}\mathrm{P}(\omega)
  $$if 
  $$
  \mathrm{E}(\left\vert X \right\vert ) = \int_\Omega \left\vert X(\omega) \right\vert \mathrm{d}\mathrm{P}(\omega) < \infty
  $$

- Jensen's Inequality

  For a convex, real-valued function $\varphi$ defined on $\mathbb{R}$, if $\mathrm{E}(\left\vert X \right\vert ) < \infty$ and $\mathrm{E}(\varphi(X)) < \infty$, then 
  $$
  \varphi(\mathrm{E}(X)) \leqslant \mathrm{E}(\varphi(X))
  $$

### Change of Measure

Consider a random variable $Z$, let $\mathrm{E}(Z) = 1$ and $Z \geqslant 0$. For event $A \in \mathcal{F}$, define 
$$
\tilde{\mathrm{P}}(A) = \int_A Z(\omega) \mathrm{d}\mathrm{P}(\omega)
$$Then $\tilde{\mathrm{P}}$ is a probability measure and $\tilde{\mathrm{E}}(X) = \mathrm{E}(XZ)$.

If $Z > 0$, then 
$$
\mathrm{E}(Y) = \tilde{\mathrm{E}}\left(\frac{Y}{Z}\right)
$$

- Equivalent Probability Measure

  - Definition

    Let $(\Omega,\ \mathcal{F})$ be a measurable space. Two Probability measures $\mathrm{P}$ and $\tilde{\mathrm{P}}$ on $(\Omega,\ \mathcal{F})$ are equivalent if they agree on zero probability events, i.e., $\mathrm{P}(A)=0 \iff $.